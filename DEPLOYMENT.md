# üöÄ Guia de Deployment - Scrape TH API

## Status Atual
‚úÖ **Vers√£o:** 3.2 - PRONTO PARA PRODU√á√ÉO
‚úÖ **Data:** 2026-01-06
‚úÖ **Branch:** main
‚úÖ **Deploy:** EasyPanel

---

## üìã Resumo da Implementa√ß√£o

### Arquitetura
```
FastAPI (Async)
    ‚Üì
Job Queue (Threading)
    ‚Üì
Playwright Sync (Browser Automation)
    ‚Üì
Webhook Caller (Retry Logic)
```

### Features Implementadas

#### ‚úÖ Job Queue + Webhook
- Execu√ß√£o em background via threading
- Webhook callbacks com retry logic (exponencial: 2s, 4s, 8s)
- Status polling: pending ‚Üí processing ‚Üí completed/failed
- Suporte a m√∫ltiplos jobs simult√¢neos

#### ‚úÖ Playwright Migration
- Migra√ß√£o completa de Selenium para Playwright
- Sync API (n√£o async)
- Chromium pr√©-instalado no Docker
- Performance: ~4-5 minutos para 50 canais

#### ‚úÖ Vari√°veis Din√¢micas
- Credenciais por request com fallback .env
- Scrape URL customiz√°vel
- Wait time ajust√°vel
- Webhook URL customiz√°vel

#### ‚úÖ Health Check
- Endpoint: `GET /api/v1/tubehunt/health`
- Retorna status de todos os servi√ßos
- Uptime tracking
- Ideal para monitoramento

#### ‚úÖ Limpeza de Produ√ß√£o
- 5 arquivos desnecess√°rios removidos
- Projeto reduzido de 21 para 16 arquivos Python
- Sem depend√™ncias de async browser
- Sem Selenium (deprecated)

---

## üîß Configura√ß√£o no EasyPanel

### Vari√°veis de Ambiente Necess√°rias

```env
# Credenciais TubeHunt (obrigat√≥rios como fallback)
TUBEHUNT_LOGIN_URL=https://app.tubehunt.io/login
TUBEHUNT_USER=seu_email@gmail.com
TUBEHUNT_PASSWORD=sua_senha

# API Configuration
API_HOST=0.0.0.0
API_PORT=80
LOG_LEVEL=INFO
```

### Health Check Setup (IMPORTANTE)

1. **Health Check Path:** `/api/v1/tubehunt/health`
2. **Health Check Interval:** `30 segundos`
3. **Health Check Timeout:** `10 segundos`
4. **Health Check Retries:** `3`

### Requisitos de Recursos

- **Memory:** M√≠nimo 1GB (Playwright + Chromium)
- **CPU:** M√≠nimo 1 core
- **Disk:** ~500MB para Chromium

---

## üì° Endpoints Dispon√≠veis

### 1. Health Check
```bash
GET /api/v1/tubehunt/health
```
**Response:** `200 OK`
```json
{
  "status": "ok",
  "version": "1.5",
  "services": {
    "api": "healthy",
    "selenium": "healthy"
  },
  "uptime_seconds": 3600.5,
  "message": "API est√° funcionando corretamente"
}
```

### 2. Iniciar Job de Scraping
```bash
POST /api/v1/tubehunt/scrape-channels/start
```

**Request (todos os campos opcionais):**
```json
{
  "login_url": "https://app.tubehunt.io/login",
  "username": "custom@email.com",
  "password": "custom_password",
  "scrape_url": "https://app.tubehunt.io/long/?page=2&OrderBy=DateDESC&ChangePerPage=50",
  "webhook_url": "https://seu-webhook.com/endpoint",
  "wait_time": 20
}
```

**Response:** `200 OK`
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "message": "Job criado com sucesso",
  "created_at": "2026-01-06T22:15:09.330000"
}
```

### 3. Obter Status do Job
```bash
GET /api/v1/tubehunt/scrape-channels/result/{job_id}
```

**Response - Pending:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "created_at": "2026-01-06T22:15:09.330000"
}
```

**Response - Processing:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "processing",
  "progress": 45,
  "message": "Navegando para p√°gina de canais...",
  "created_at": "2026-01-06T22:15:09.330000"
}
```

**Response - Completed:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "result": {
    "total_canais": 50,
    "canais": [
      {
        "channel_name": "Nome do Canal",
        "channel_link": "https://www.youtube.com/...",
        "subscribers": "1M"
      }
    ]
  },
  "execution_time_seconds": 245.5,
  "created_at": "2026-01-06T22:15:09.330000"
}
```

**Response - Failed:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "failed",
  "error": "Erro ao fazer login",
  "failed_at": "2026-01-06T22:15:09.330000",
  "created_at": "2026-01-06T22:15:09.330000"
}
```

---

## üîÑ Fluxo de Uso (Recomendado)

### 1. Iniciar Scraping
```bash
curl -X POST https://fulled-th-scrape.nbshm6.easypanel.host/api/v1/tubehunt/scrape-channels/start \
  -H "Content-Type: application/json" \
  -d '{
    "scrape_url": "https://app.tubehunt.io/long/?page=2&OrderBy=DateDESC&ChangePerPage=50",
    "webhook_url": "https://seu-webhook.com/callback",
    "wait_time": 20
  }'
```

### 2. Recebe job_id na resposta
```
Exemplo: "550e8400-e29b-41d4-a716-446655440000"
```

### 3. Fazer polling para status
```bash
# A cada 3-5 segundos
curl -X GET https://fulled-th-scrape.nbshm6.easypanel.host/api/v1/tubehunt/scrape-channels/result/550e8400-e29b-41d4-a716-446655440000
```

### 4. Webhook Callback Autom√°tico
Quando o job terminar com `status: "completed"`, a API automaticamente envia POST para `webhook_url` com:
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "result": {
    "total_canais": 50,
    "canais": [...]
  },
  "execution_time_seconds": 245.5
}
```

---

## üê≥ Docker - Otimiza√ß√µes para EasyPanel

### Dockerfile Changes
- ‚úÖ `--workers 1`: Reduz mem√≥ria de ~800MB para ~300MB
- ‚úÖ `--timeout-keep-alive 75`: Conex√µes mais eficientes
- ‚úÖ `.dockerignore`: Build mais r√°pido
- ‚úÖ Python 3.11 slim: Base otimizada

### Build Context
```
Repository: https://github.com/felipealfah/th_scrape.git
Branch: main
Dockerfile: ./Dockerfile
Build Context: . (raiz)
Port: 8000 (mapeado para porta do EasyPanel)
```

---

## ‚úÖ Checklist de Deployment

- [ ] Vari√°veis de ambiente configuradas no EasyPanel
- [ ] Memory limit: 1GB ou mais
- [ ] Health check path: `/api/v1/tubehunt/health`
- [ ] Porta mapeada corretamente (8000 ‚Üí porta do EasyPanel)
- [ ] CORS habilitado (j√° est√° `allow_origins: ["*"]`)
- [ ] Rebuild imagem Docker a partir de `main` branch
- [ ] Testar health check: `curl https://fulled-th-scrape.nbshm6.easypanel.host/api/v1/tubehunt/health`
- [ ] Testar in√≠cio de job
- [ ] Testar polling de status

---

## üêõ Troubleshooting

### Erro: "No such option: --timeout"
‚úÖ **Resolvido** - Usar `--timeout-keep-alive` ao inv√©s

### Erro: 502 Bad Gateway
‚ùå **Causa:** Falta de mem√≥ria ou timeout
‚úÖ **Solu√ß√£o:** Aumentar memory limit para 1GB+ no EasyPanel

### Erro: "Connection refused" em health check
‚ùå **Causa:** Container n√£o iniciou
‚úÖ **Solu√ß√£o:** Verificar logs do Docker, aumentar timeout de health check

### Job n√£o retorna resultado
‚ùå **Causa:** Job ainda processando
‚úÖ **Solu√ß√£o:** Esperar mais tempo (at√© 360 segundos) e fazer polling novamente

---

## üìû Contato & Suporte

**Projeto:** Scrape TH API
**Vers√£o:** 3.2
**Desenvolvedor:** Felipe Full
**Data:** 2026-01-06
**Status:** Production Ready ‚úÖ

---

## üîê Security Notes

- ‚úÖ CORS habilitado para todas as origens (ajustar em produ√ß√£o se necess√°rio)
- ‚úÖ Sem autentica√ß√£o na API (adicionar se necess√°rio)
- ‚úÖ Vari√°veis sens√≠veis (.env) n√£o versionadas
- ‚úÖ Logs n√£o exp√µem senhas completas

---

## üìà Performance Esperada

- **Tempo de startup:** ~10-15 segundos
- **Tempo de scraping:** ~4-5 minutos (50 canais)
- **Mem√≥ria em repouso:** ~300MB
- **Mem√≥ria durante scraping:** ~600-800MB
- **Threads simult√¢neas:** 1 (workers=1)

---

**√öltima atualiza√ß√£o:** 2026-01-06
**Pr√≥xima revis√£o:** 2026-01-13
